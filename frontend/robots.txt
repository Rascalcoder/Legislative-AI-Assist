# Competition Law AI Assistant - Robots.txt
# Allow all search engines to index the site

User-agent: *
Allow: /

# Sitemap location
Sitemap: https://yourdomain.com/sitemap.xml

# Crawl-delay (optional, helps prevent server overload)
Crawl-delay: 1

# Specific rules for common bots
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

# Block access to potential API endpoints if served from same domain
# (Uncomment if API is on same domain and you don't want it indexed)
# Disallow: /api/

